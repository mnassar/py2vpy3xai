{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrem4VJQk7zoUTuinFaA8Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mnassar/py2vpy3xai/blob/main/py2vpy3XaiLemnaLikeScript.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "@author: mnassar\n",
        "\n",
        "This is the code used to generate the results for the Lime text explainer at the char level with a surrounding window of the best position found. We consider this approach as inspired by the Lemna paper so we call it the Lemna like explainer.\n",
        "\n",
        "This is used to generate the results for Table 10: Results for LIMETextExplainer at the char level\n",
        "with a custom fused LASSO regressor"
      ],
      "metadata": {
        "id": "0i3aUqW6kMLM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install lime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1o4_vXWYxIoI",
        "outputId": "bb674016-dd91-4635-e13d-94199160c82d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting lime\n",
            "  Downloading lime-0.2.0.1.tar.gz (275 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m275.7/275.7 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from lime) (3.7.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from lime) (1.25.2)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from lime) (1.11.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from lime) (4.66.2)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from lime) (1.2.2)\n",
            "Requirement already satisfied: scikit-image>=0.12 in /usr/local/lib/python3.10/dist-packages (from lime) (0.19.3)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (3.2.1)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (9.4.0)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2.31.6)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (2024.2.12)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (1.6.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from scikit-image>=0.12->lime) (24.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->lime) (3.4.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (4.50.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->lime) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->lime) (1.16.0)\n",
            "Building wheels for collected packages: lime\n",
            "  Building wheel for lime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for lime: filename=lime-0.2.0.1-py3-none-any.whl size=283835 sha256=207d172cea2a1fe2439efed93330e2cdb4849c3dbb2f57a141dcf77295296b06\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/a2/af/9ac0a1a85a27f314a06b39e1f492bee1547d52549a4606ed89\n",
            "Successfully built lime\n",
            "Installing collected packages: lime\n",
            "Successfully installed lime-0.2.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-nS-wBD6wNLr"
      },
      "outputs": [],
      "source": [
        "%%time\n",
        "\n",
        "# -*- coding: utf-8 -*-\n",
        "\n",
        "# !pip install lime\n",
        "\n",
        "\n",
        "import lime\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "from keras.utils import pad_sequences\n",
        "from keras import models\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model._base import LinearModel,RegressorMixin\n",
        "from sklearn.linear_model import Ridge, LinearRegression\n",
        "import cvxpy as cp\n",
        "import re\n",
        "\n",
        "\n",
        "#longest common subsequence\n",
        "def lcs(X, Y):\n",
        "    # find the length of the strings\n",
        "    m = len(X)\n",
        "    n = len(Y)\n",
        "    # declaring the array for storing the dp values\n",
        "    L = [[None]*(n + 1) for i in range(m + 1)]\n",
        "    \"\"\"Following steps build L[m + 1][n + 1] in bottom up fashion\n",
        "    Note: L[i][j] contains length of LCS of X[0..i-1]\n",
        "    and Y[0..j-1]\"\"\"\n",
        "    for i in range(m+1):\n",
        "        for j in range(n+1):\n",
        "            if i == 0 or j == 0 :\n",
        "                L[i][j] = 0\n",
        "            elif X[i-1] == Y[j-1]:\n",
        "                L[i][j] = L[i-1][j-1]+1\n",
        "            else:\n",
        "                L[i][j] = 0\n",
        "    return max ( max(l) for l in L )\n",
        "\n",
        "def eval_expl(r, col):\n",
        "  if re.search(re.compile(r'\\bu[\\'|\\\"]\\s*\\S+'), r[col]):\n",
        "    return True\n",
        "  return lcs(r[\"explanation\"], r[col]) >= EXPL_EVAL_THR\n",
        "\n",
        "\n",
        "\n",
        "def predict (lines, shape = 1):\n",
        "  samples = [  bytearray(line, encoding=\"utf-8\") for line in lines ]\n",
        "  samples_padded = pad_sequences(samples, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "  preds = m.predict(samples_padded)\n",
        "  # if pred < 0.5:\n",
        "  #   label=\"python2\"\n",
        "  # else:\n",
        "  #   label=\"python3\"\n",
        "  if shape == 2:\n",
        "    return np.concatenate ([1-preds, preds], axis=1)\n",
        "  else:\n",
        "    return preds\n",
        "\n",
        "\n",
        "def explain(line):\n",
        "  # exp = explainer.explain_instance(line, lambda x: predict(x, shape=2), num_features=1, model_regressor=FusedLassoRegressor(),\n",
        "                                  #  num_samples=10*32) # more makes the code very slow\n",
        "  exp = explainer.explain_instance(line, lambda x: predict(x, shape=2), num_features=1,\n",
        "                                   num_samples=10*32) # more makes the code very slow\n",
        "  idx = exp.as_map()[1][0][0]\n",
        "  # print(idx)\n",
        "  return line [max(0, idx - WIN_SIZE//2 - 1):min(idx + WIN_SIZE//2 + 1, len(line))]\n",
        "\n",
        "\n",
        "class FusedLassoRegressor(LinearModel, RegressorMixin):\n",
        "  def fit(self, X, y, sample_weight=None):\n",
        "    n_samples, n_feat = X.shape\n",
        "    beta = cp.Variable(n_feat)\n",
        "    forwardDiff = beta[1:] - beta[0:-1]\n",
        "    objective = cp.Minimize(cp.sum_squares(X @ beta - y) + 10**4 * cp.norm(forwardDiff,2))\n",
        "    prob = cp.Problem(objective)\n",
        "    result = prob.solve()\n",
        "    self.coef_ = beta.value\n",
        "    self.intercept_ = 0\n",
        "    return self\n",
        "\n",
        "\n",
        "model_str = 'MM_dataset10k_Win5_NF32.keras'\n",
        "# model_str = 'MM_dataset10k_Win5_NF64.keras'\n",
        "# model_str = 'MM_dataset10k_Win5_NF128.keras'\n",
        "# model_str = 'MM_dataset10k_Win7_NF32.keras'\n",
        "# model_str = 'MM_dataset10k_Win7_NF64.keras'\n",
        "# model_str = 'MM_dataset10k_Win7_NF128.keras'\n",
        "# model_str = 'MM_dataset10k_Win10_NF32.keras'\n",
        "# model_str = 'MM_dataset10k_Win10_NF64.keras'\n",
        "# model_str = 'MM_dataset10k_Win10_NF128.keras'\n",
        "m = models.load_model(model_str)\n",
        "MAX_LEN = 100\n",
        "WIN_SIZE = int (model_str.split(\"_\")[2][3:])\n",
        "EXPL_WIN = WIN_SIZE + 3\n",
        "EXPL_EVAL_THR = 3\n",
        "dataset = model_str.split(\"_\")[1]+\".csv\"\n",
        "m.summary()\n",
        "\n",
        "print(WIN_SIZE)\n",
        "print(dataset)\n",
        "\n",
        "\n",
        "# Explain for dataset\n",
        "\n",
        "# prepare data once for all\n",
        "df = pd.read_csv(dataset, dtype={\n",
        "    '__future__': 'object',\n",
        "    'xrange': 'object'})\n",
        "df = df.drop ( df[df[\"lines of code\"].isnull()].index )\n",
        "\n",
        "# consider only lines with annotated explanations\n",
        "df_expl = df[df[\"explanation\"].notnull()]\n",
        "# add predictions\n",
        "df_expl = df_expl.join( pd.Series(name=\"pred\", data = predict(df_expl[\"lines of code\"]).reshape(-1), index=df_expl.index) )\n",
        "# consider only correct predictions\n",
        "df_expl[\"pred_class\"] = df_expl[\"pred\"].map(lambda x: 3 if x>0.5 else 2)\n",
        "df_expl = df_expl.loc[df_expl[\"pred_class\"] == df_expl[\"class\"]]\n",
        "\n",
        "#char level explainer\n",
        "explainer = LimeTextExplainer(class_names=[\"py2\", \"py3\"], char_level=True, bow=False)\n",
        "\n",
        "\n",
        "df_small = df_expl.copy()\n",
        "df_small['lemna'] = df_small['lines of code'].map(explain)\n",
        "\n",
        "df_small[\"acc_expl_lemna\"] = df_small.apply(eval_expl, col=\"lemna\", axis=1)\n",
        "acc = sum(df_small[\"acc_expl_lemna\"])\n",
        "print (f\"{acc}/{df_small.shape[0]}\")\n",
        "print (f\"{acc * 100 / df_small.shape[0]:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# -*- coding: utf-8 -*-\n",
        "\"\"\"py2vpy3XaiLemna.ipynb\n",
        "\n",
        "Automatically generated by Colaboratory.\n",
        "\n",
        "Original file is located at\n",
        "    https://colab.research.google.com/drive/14c9sxygiZNsY6OpPvlxvyrgj5TazVQDU\n",
        "\n",
        "Shap\n",
        "\"\"\"\n",
        "\n",
        "# !pip install lime\n",
        "\n",
        "\n",
        "import lime\n",
        "from lime.lime_text import LimeTextExplainer\n",
        "from keras.utils import pad_sequences\n",
        "from keras import models\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.linear_model._base import LinearModel,RegressorMixin\n",
        "from sklearn.linear_model import Ridge, LinearRegression\n",
        "import cvxpy as cp\n",
        "import re\n",
        "\n",
        "\n",
        "#longest common subsequence\n",
        "def lcs(X, Y):\n",
        "    # find the length of the strings\n",
        "    m = len(X)\n",
        "    n = len(Y)\n",
        "    # declaring the array for storing the dp values\n",
        "    L = [[None]*(n + 1) for i in range(m + 1)]\n",
        "    \"\"\"Following steps build L[m + 1][n + 1] in bottom up fashion\n",
        "    Note: L[i][j] contains length of LCS of X[0..i-1]\n",
        "    and Y[0..j-1]\"\"\"\n",
        "    for i in range(m+1):\n",
        "        for j in range(n+1):\n",
        "            if i == 0 or j == 0 :\n",
        "                L[i][j] = 0\n",
        "            elif X[i-1] == Y[j-1]:\n",
        "                L[i][j] = L[i-1][j-1]+1\n",
        "            else:\n",
        "                L[i][j] = 0\n",
        "    return max ( max(l) for l in L )\n",
        "\n",
        "def eval_expl(r, col):\n",
        "  if re.search(re.compile(r'\\bu[\\'|\\\"]\\s*\\S+'), r[col]):\n",
        "    return True\n",
        "  return lcs(r[\"explanation\"], r[col]) >= EXPL_EVAL_THR\n",
        "\n",
        "\n",
        "\n",
        "def predict (lines, shape = 1):\n",
        "  samples = [  bytearray(line, encoding=\"utf-8\") for line in lines ]\n",
        "  samples_padded = pad_sequences(samples, maxlen=MAX_LEN, padding='post', truncating='post')\n",
        "  preds = m.predict(samples_padded)\n",
        "  # if pred < 0.5:\n",
        "  #   label=\"python2\"\n",
        "  # else:\n",
        "  #   label=\"python3\"\n",
        "  if shape == 2:\n",
        "    return np.concatenate ([1-preds, preds], axis=1)\n",
        "  else:\n",
        "    return preds\n",
        "\n",
        "\n",
        "def explain(line):\n",
        "  # exp = explainer.explain_instance(line, lambda x: predict(x, shape=2), num_features=1, model_regressor=FusedLassoRegressor(),\n",
        "                                  #  num_samples=10*32) # more makes the code very slow\n",
        "  exp = explainer.explain_instance(line, lambda x: predict(x, shape=2), num_features=1, num_samples=10*32)\n",
        "  idx = exp.as_map()[1][0][0]\n",
        "  # print(idx)\n",
        "  return line [max(0, idx - WIN_SIZE//2 - 1):min(idx + WIN_SIZE//2 + 1, len(line))]\n",
        "\n",
        "\n",
        "class FusedLassoRegressor(LinearModel, RegressorMixin):\n",
        "  def fit(self, X, y, sample_weight=None):\n",
        "    n_samples, n_feat = X.shape\n",
        "    beta = cp.Variable(n_feat)\n",
        "    forwardDiff = beta[1:] - beta[0:-1]\n",
        "    objective = cp.Minimize(cp.sum_squares(X @ beta - y) + 10**4 * cp.norm(forwardDiff,2))\n",
        "    prob = cp.Problem(objective)\n",
        "    result = prob.solve()\n",
        "    self.coef_ = beta.value\n",
        "    self.intercept_ = 0\n",
        "    return self\n",
        "\n",
        "with open(\"output.txt\", 'w') as f:\n",
        "\n",
        "  for model_str in ['MM_dataset10k_Win10_NF32.keras',\n",
        "                    'MM_dataset10k_Win10_NF64.keras',\n",
        "                    'MM_dataset10k_Win10_NF128.keras']:\n",
        "                    # ,\n",
        "                    # 'MM_dataset10k_Win5_NF128.keras',\n",
        "                    # 'MM_dataset10k_Win7_NF32.keras',\n",
        "                    # 'MM_dataset10k_Win7_NF64.keras',\n",
        "                    # 'MM_dataset10k_Win7_NF128.keras',\n",
        "                    # 'MM_dataset10k_Win10_NF32.keras',\n",
        "                    # 'MM_dataset10k_Win10_NF64.keras']:\n",
        "\n",
        "    m = models.load_model(model_str)\n",
        "    MAX_LEN = 100\n",
        "    WIN_SIZE = int (model_str.split(\"_\")[2][3:])\n",
        "    EXPL_WIN = WIN_SIZE + 3\n",
        "    EXPL_EVAL_THR = 3\n",
        "    dataset = model_str.split(\"_\")[1]+\".csv\"\n",
        "    m.summary()\n",
        "\n",
        "    print(WIN_SIZE)\n",
        "    print(dataset)\n",
        "\n",
        "\n",
        "    # Explain for dataset\n",
        "\n",
        "    # prepare data once for all\n",
        "    df = pd.read_csv(dataset, dtype={\n",
        "        '__future__': 'object',\n",
        "        'xrange': 'object'})\n",
        "    df = df.drop ( df[df[\"lines of code\"].isnull()].index )\n",
        "\n",
        "    # consider only lines with annotated explanations\n",
        "    df_expl = df[df[\"explanation\"].notnull()]\n",
        "    # add predictions\n",
        "    df_expl = df_expl.join( pd.Series(name=\"pred\", data = predict(df_expl[\"lines of code\"]).reshape(-1), index=df_expl.index) )\n",
        "    # consider only correct predictions\n",
        "    df_expl[\"pred_class\"] = df_expl[\"pred\"].map(lambda x: 3 if x>0.5 else 2)\n",
        "    df_expl = df_expl.loc[df_expl[\"pred_class\"] == df_expl[\"class\"]]\n",
        "\n",
        "    #char level explainer\n",
        "    explainer = LimeTextExplainer(class_names=[\"py2\", \"py3\"], char_level=True, bow=False)\n",
        "\n",
        "\n",
        "    df_small = df_expl.copy()\n",
        "    df_small['lemna'] = df_small['lines of code'].map(explain)\n",
        "\n",
        "    df_small[\"acc_expl_lemna\"] = df_small.apply(eval_expl, col=\"lemna\", axis=1)\n",
        "    acc = sum(df_small[\"acc_expl_lemna\"])\n",
        "    print (f\"{acc}/{df_small.shape[0]}\")\n",
        "    print (f\"{acc * 100 / df_small.shape[0]:.2f}\")\n",
        "    f.write(f\"{acc * 100 / df_small.shape[0]:.2f}\\n\")\n"
      ],
      "metadata": {
        "id": "7XDHFZsPyww5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}